\list 
(1)RYGB
(2)Band
(3)BPD-DS
(4)SADI-S 
relative treatment effect
ForestDRLearner with random forest

Death
[(-3.345044882599476, array([nan, nan])), (-9.52411080539015, array([nan, nan])), (30.722102657997457, array([nan, nan])), (5.798242676954597, array([nan, nan]))]
[(-3.345044882599476, array([nan, nan])), (-9.52411080539015, array([nan, nan])), (30.722102657997457, array([nan, nan])), (5.798242676954597, array([nan, nan]))]

intervention
[(-12.368325435765756, array([nan, nan])), (-19.15067013281516, array([nan, nan])), (-13.046209232474958, array([nan, nan])), (-0.15930938609076115, array([nan, nan]))]
[(-12.368325435765756, array([nan, nan])), (-19.15067013281516, array([nan, nan])), (-13.046209232474958, array([nan, nan])), (-0.15930938609076115, array([nan, nan]))]

readmission
[(40.934849917184984, array([nan, nan])), (-19.688028303762866, array([nan, nan])), (-18.117575770615645, array([nan, nan])), (7.282612468395561, array([nan, nan]))]
[(40.934849917184984, array([nan, nan])), (-19.688028303762866, array([nan, nan])), (-18.117575770615645, array([nan, nan])), (7.282612468395561, array([nan, nan]))]

reoperation
[(-2.7146369478094905, array([nan, nan])), (-19.27553426129943, array([nan, nan])), (-15.879988252498428, array([nan, nan])), (-8.457118271811916, array([nan, nan]))]
[(-2.7146369478094905, array([nan, nan])), (-19.27553426129943, array([nan, nan])), (-15.879988252498428, array([nan, nan])), (-8.457118271811916, array([nan, nan]))]
ForestDRLearner with lgbm

Death
ForestDRLearner + 
[LightGBM] [Info] Number of positive: 99050, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042691 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 347008, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285440 -> initscore=-0.917635
[LightGBM] [Info] Start training from score -0.917635
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038369 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 347008, number of used features: 49
[LightGBM] [Info] Start training from score 0.000130
[LightGBM] [Info] Number of positive: 99050, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019766 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 347009, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285439 -> initscore=-0.917639
[LightGBM] [Info] Start training from score -0.917639
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021718 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 347009, number of used features: 49
[LightGBM] [Info] Start training from score 0.000173
[LightGBM] [Info] Number of positive: 5003, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016148 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252961, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019778 -> initscore=-3.903222
[LightGBM] [Info] Start training from score -3.903222
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014770 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252961, number of used features: 49
[LightGBM] [Info] Start training from score 0.000138
[LightGBM] [Info] Number of positive: 5003, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014861 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252962, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019778 -> initscore=-3.903226
[LightGBM] [Info] Start training from score -3.903226
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014728 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252962, number of used features: 49
[LightGBM] [Info] Start training from score 0.000107
[LightGBM] [Info] Number of positive: 4638, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017470 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 347
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018361 -> initscore=-3.978976
[LightGBM] [Info] Start training from score -3.978976
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016130 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 48
[LightGBM] [Info] Start training from score 0.000111
[LightGBM] [Info] Number of positive: 4637, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013187 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 347
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018357 -> initscore=-3.979196
[LightGBM] [Info] Start training from score -3.979196
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013998 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 48
[LightGBM] [Info] Start training from score 0.000146
[LightGBM] [Info] Number of positive: 8092, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018211 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 256050, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031603 -> initscore=-3.422383
[LightGBM] [Info] Start training from score -3.422383
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017643 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 256050, number of used features: 49
[LightGBM] [Info] Start training from score 0.000137
[LightGBM] [Info] Number of positive: 8092, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013504 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 256051, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031603 -> initscore=-3.422387
[LightGBM] [Info] Start training from score -3.422387
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016585 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 256051, number of used features: 49
[LightGBM] [Info] Start training from score 0.000121
[(1.8248061000923528, array([nan, nan])), (0.40686886273738954, array([nan, nan])), (2.3022773950763957, array([nan, nan])), (2.393249279999271, array([nan, nan]))]
[(1.8248061000923528, array([nan, nan])), (0.40686886273738954, array([nan, nan])), (2.3022773950763957, array([nan, nan])), (2.393249279999271, array([nan, nan]))]

intervention
ForestDRLearner
[LightGBM] [Info] Number of positive: 99050, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036337 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 347008, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285440 -> initscore=-0.917635
[LightGBM] [Info] Start training from score -0.917635
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026510 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 347008, number of used features: 49
[LightGBM] [Info] Start training from score 0.012297
[LightGBM] [Info] Number of positive: 99050, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021593 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 347009, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285439 -> initscore=-0.917639
[LightGBM] [Info] Start training from score -0.917639
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021032 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 347009, number of used features: 49
[LightGBM] [Info] Start training from score 0.012000
[LightGBM] [Info] Number of positive: 5003, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017214 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252961, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019778 -> initscore=-3.903222
[LightGBM] [Info] Start training from score -3.903222
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016262 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252961, number of used features: 49
[LightGBM] [Info] Start training from score 0.007689
[LightGBM] [Info] Number of positive: 5003, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019002 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 347
[LightGBM] [Info] Number of data points in the train set: 252962, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019778 -> initscore=-3.903226
[LightGBM] [Info] Start training from score -3.903226
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023060 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252962, number of used features: 48
[LightGBM] [Info] Start training from score 0.007887
[LightGBM] [Info] Number of positive: 4638, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017743 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018361 -> initscore=-3.978976
[LightGBM] [Info] Start training from score -3.978976
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017784 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 49
[LightGBM] [Info] Start training from score 0.008044
[LightGBM] [Info] Number of positive: 4637, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 347
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018357 -> initscore=-3.979196
[LightGBM] [Info] Start training from score -3.979196
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014959 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 48
[LightGBM] [Info] Start training from score 0.008231
[LightGBM] [Info] Number of positive: 8092, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030188 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 256050, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031603 -> initscore=-3.422383
[LightGBM] [Info] Start training from score -3.422383
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021027 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 256050, number of used features: 49
[LightGBM] [Info] Start training from score 0.008846
[LightGBM] [Info] Number of positive: 8092, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017371 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 256051, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031603 -> initscore=-3.422387
[LightGBM] [Info] Start training from score -3.422387
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017279 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 256051, number of used features: 49
[LightGBM] [Info] Start training from score 0.008576
[(2.815731118341842, array([nan, nan])), (1.0806150182540568, array([nan, nan])), (3.1230801399274686, array([nan, nan])), (3.472817344377556, array([nan, nan]))]
[(2.815731118341842, array([nan, nan])), (1.0806150182540568, array([nan, nan])), (3.1230801399274686, array([nan, nan])), (3.472817344377556, array([nan, nan]))]

readmission
ForestDRLearner
[LightGBM] [Info] Number of positive: 99050, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023078 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 347008, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285440 -> initscore=-0.917635
[LightGBM] [Info] Start training from score -0.917635
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025837 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 347008, number of used features: 49
[LightGBM] [Info] Start training from score 0.037184
[LightGBM] [Info] Number of positive: 99050, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018876 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 347009, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285439 -> initscore=-0.917639
[LightGBM] [Info] Start training from score -0.917639
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020145 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 347009, number of used features: 49
[LightGBM] [Info] Start training from score 0.037463
[LightGBM] [Info] Number of positive: 5003, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019298 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252961, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019778 -> initscore=-3.903222
[LightGBM] [Info] Start training from score -3.903222
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016461 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252961, number of used features: 49
[LightGBM] [Info] Start training from score 0.028953
[LightGBM] [Info] Number of positive: 5003, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022890 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252962, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019778 -> initscore=-3.903226
[LightGBM] [Info] Start training from score -3.903226
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015621 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252962, number of used features: 49
[LightGBM] [Info] Start training from score 0.028281
[LightGBM] [Info] Number of positive: 4638, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017497 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018361 -> initscore=-3.978976
[LightGBM] [Info] Start training from score -3.978976
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020066 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 49
[LightGBM] [Info] Start training from score 0.029482
[LightGBM] [Info] Number of positive: 4637, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015920 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018357 -> initscore=-3.979196
[LightGBM] [Info] Start training from score -3.979196
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015910 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 49
[LightGBM] [Info] Start training from score 0.029478
[LightGBM] [Info] Number of positive: 8092, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031026 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 256050, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031603 -> initscore=-3.422383
[LightGBM] [Info] Start training from score -3.422383
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032552 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 256050, number of used features: 49
[LightGBM] [Info] Start training from score 0.030080
[LightGBM] [Info] Number of positive: 8092, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019709 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 256051, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031603 -> initscore=-3.422387
[LightGBM] [Info] Start training from score -3.422387
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017551 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 256051, number of used features: 49
[LightGBM] [Info] Start training from score 0.029885
[(1.9294548841579116, array([nan, nan])), (0.8694631119021795, array([nan, nan])), (2.459380069802151, array([nan, nan])), (1.7230788636394596, array([nan, nan]))]
[(1.9294548841579116, array([nan, nan])), (0.8694631119021795, array([nan, nan])), (2.459380069802151, array([nan, nan])), (1.7230788636394596, array([nan, nan]))]

reoperation
ForestDRLearner
[LightGBM] [Info] Number of positive: 99050, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022887 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 347008, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285440 -> initscore=-0.917635
[LightGBM] [Info] Start training from score -0.917635
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022827 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 347008, number of used features: 49
[LightGBM] [Info] Start training from score 0.011755
[LightGBM] [Info] Number of positive: 99050, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022846 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 347009, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285439 -> initscore=-0.917639
[LightGBM] [Info] Start training from score -0.917639
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023256 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 347009, number of used features: 49
[LightGBM] [Info] Start training from score 0.011743
[LightGBM] [Info] Number of positive: 5003, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023969 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252961, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019778 -> initscore=-3.903222
[LightGBM] [Info] Start training from score -3.903222
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019603 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252961, number of used features: 49
[LightGBM] [Info] Start training from score 0.007721
[LightGBM] [Info] Number of positive: 5003, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035021 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252962, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019778 -> initscore=-3.903226
[LightGBM] [Info] Start training from score -3.903226
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023258 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252962, number of used features: 49
[LightGBM] [Info] Start training from score 0.007930
[LightGBM] [Info] Number of positive: 4638, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018088 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018361 -> initscore=-3.978976
[LightGBM] [Info] Start training from score -3.978976
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018417 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 49
[LightGBM] [Info] Start training from score 0.008231
[LightGBM] [Info] Number of positive: 4637, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015113 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 347
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018357 -> initscore=-3.979196
[LightGBM] [Info] Start training from score -3.979196
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016010 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 252596, number of used features: 48
[LightGBM] [Info] Start training from score 0.008262
[LightGBM] [Info] Number of positive: 8092, number of negative: 247958
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036818 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 256050, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031603 -> initscore=-3.422383
[LightGBM] [Info] Start training from score -3.422383
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016241 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 256050, number of used features: 49
[LightGBM] [Info] Start training from score 0.008616
[LightGBM] [Info] Number of positive: 8092, number of negative: 247959
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022038 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 349
[LightGBM] [Info] Number of data points in the train set: 256051, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031603 -> initscore=-3.422387
[LightGBM] [Info] Start training from score -3.422387
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018466 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 351
[LightGBM] [Info] Number of data points in the train set: 256051, number of used features: 49
[LightGBM] [Info] Start training from score 0.008651
[(2.603925897207946, array([nan, nan])), (1.0468296583747634, array([nan, nan])), (4.310001244576553, array([nan, nan])), (3.1476222728430217, array([nan, nan]))]
[(2.603925897207946, array([nan, nan])), (1.0468296583747634, array([nan, nan])), (4.310001244576553, array([nan, nan])), (3.1476222728430217, array([nan, nan]))]
ForestDRLearner with xgboost

Death
[(1.5551733209973837, array([nan, nan])), (2.9114398340700873, array([nan, nan])), (-3.562738480752689, array([nan, nan])), (3.2880207253943925, array([nan, nan]))]
[(1.5551733209973837, array([nan, nan])), (2.9114398340700873, array([nan, nan])), (-3.562738480752689, array([nan, nan])), (3.2880207253943925, array([nan, nan]))]

intervention
[(2.8346917606692563, array([nan, nan])), (0.9293524584744134, array([nan, nan])), (-5.9033029925867115, array([nan, nan])), (3.617938969138403, array([nan, nan]))]
[(2.8346917606692563, array([nan, nan])), (0.9293524584744134, array([nan, nan])), (-5.9033029925867115, array([nan, nan])), (3.617938969138403, array([nan, nan]))]

readmission
[(1.9241926906706992, array([nan, nan])), (0.862929784441108, array([nan, nan])), (1.866179739392833, array([nan, nan])), (1.917470235083423, array([nan, nan]))]
[(1.9241926906706992, array([nan, nan])), (0.862929784441108, array([nan, nan])), (1.866179739392833, array([nan, nan])), (1.917470235083423, array([nan, nan]))]

reoperation
[(2.5647803908394646, array([nan, nan])), (0.9054918964033101, array([nan, nan])), (4.122288214698746, array([nan, nan])), (2.9235197814549383, array([nan, nan]))]
[(2.5647803908394646, array([nan, nan])), (0.9054918964033101, array([nan, nan])), (4.122288214698746, array([nan, nan])), (2.9235197814549383, array([nan, nan]))]
