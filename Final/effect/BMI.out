\list 
(1)RYGB
(2)Band
(3)BPD-DS
(4)SADI-S \BMI treatment effect

DragonNet
epoch: 0--------- train_loss: 3.1511521339416504
epoch: 1--------- train_loss: 2.606566905975342
epoch: 2--------- train_loss: 2.2692313194274902
epoch: 3--------- train_loss: 2.0687928199768066
epoch: 4--------- train_loss: 1.9677658081054688
epoch: 5--------- train_loss: 1.9161558151245117
epoch: 6--------- train_loss: 1.8715447187423706
epoch: 7--------- train_loss: 1.8133068084716797
epoch: 8--------- train_loss: 1.7634050846099854
epoch: 9--------- train_loss: 1.733827829360962
epoch: 10--------- train_loss: 1.7282605171203613
epoch: 11--------- train_loss: 1.7250291109085083
epoch: 12--------- train_loss: 1.721681833267212
epoch: 13--------- train_loss: 1.7183561325073242
epoch: 14--------- train_loss: 1.716931700706482
epoch: 15--------- train_loss: 1.7131576538085938
epoch: 16--------- train_loss: 1.7169703245162964
epoch: 17--------- train_loss: 1.7117118835449219
epoch: 18--------- train_loss: 1.7106385231018066
epoch: 19--------- train_loss: 1.708893060684204
epoch: 20--------- train_loss: 1.7059836387634277
epoch: 21--------- train_loss: 1.6996705532073975
epoch: 22--------- train_loss: 1.6941277980804443
epoch: 23--------- train_loss: 1.6969313621520996
epoch: 24--------- train_loss: 1.6967568397521973
epoch: 25--------- train_loss: 1.6936733722686768
epoch: 26--------- train_loss: 1.6906797885894775
epoch: 27--------- train_loss: 1.6822690963745117
epoch: 28--------- train_loss: 1.6833957433700562
epoch: 29--------- train_loss: 1.6678330898284912
epoch: 30--------- train_loss: 1.6625605821609497
epoch: 31--------- train_loss: 1.6518372297286987
epoch: 32--------- train_loss: 1.6422855854034424
epoch: 33--------- train_loss: 1.6344186067581177
epoch: 34--------- train_loss: 1.6234769821166992
epoch: 35--------- train_loss: 1.6111054420471191
epoch: 36--------- train_loss: 1.6042726039886475
epoch: 37--------- train_loss: 1.595757007598877
epoch: 38--------- train_loss: 1.5799920558929443
epoch: 39--------- train_loss: 1.5735355615615845
epoch: 40--------- train_loss: 1.5600385665893555
epoch: 41--------- train_loss: 1.5540320873260498
epoch: 42--------- train_loss: 1.5381622314453125
epoch: 43--------- train_loss: 1.5261876583099365
epoch: 44--------- train_loss: 1.5170483589172363
epoch: 45--------- train_loss: 1.498581886291504
epoch: 46--------- train_loss: 1.4839773178100586
epoch: 47--------- train_loss: 1.4775521755218506
epoch: 48--------- train_loss: 1.465988039970398
epoch: 49--------- train_loss: 1.4596433639526367
epoch: 50--------- train_loss: 1.441361665725708
epoch: 51--------- train_loss: 1.4306864738464355
epoch: 52--------- train_loss: 1.4198191165924072
epoch: 53--------- train_loss: 1.408909559249878
epoch: 54--------- train_loss: 1.3997606039047241
epoch: 55--------- train_loss: 1.379995346069336
epoch: 56--------- train_loss: 1.371462106704712
epoch: 57--------- train_loss: 1.3512163162231445
epoch: 58--------- train_loss: 1.3360756635665894
epoch: 59--------- train_loss: 1.3298156261444092
epoch: 60--------- train_loss: 1.3250768184661865
epoch: 61--------- train_loss: 1.3081324100494385
epoch: 62--------- train_loss: 1.2890620231628418
epoch: 63--------- train_loss: 1.2790203094482422
epoch: 64--------- train_loss: 1.2736506462097168
epoch: 65--------- train_loss: 1.246729850769043
epoch: 66--------- train_loss: 1.2397055625915527
epoch: 67--------- train_loss: 1.2249342203140259
epoch: 68--------- train_loss: 1.204175353050232
epoch: 69--------- train_loss: 1.18792724609375
epoch: 70--------- train_loss: 1.1710867881774902
epoch: 71--------- train_loss: 1.1672286987304688
epoch: 72--------- train_loss: 1.1573067903518677
epoch: 73--------- train_loss: 1.1467208862304688
epoch: 74--------- train_loss: 1.147702693939209
epoch: 75--------- train_loss: 1.132726788520813
epoch: 76--------- train_loss: 1.1201577186584473
epoch: 77--------- train_loss: 1.111834168434143
epoch: 78--------- train_loss: 1.1003527641296387
epoch: 79--------- train_loss: 1.0932687520980835
epoch: 80--------- train_loss: 1.080918550491333
epoch: 81--------- train_loss: 1.0676612854003906
epoch: 82--------- train_loss: 1.0594552755355835
epoch: 83--------- train_loss: 1.0486031770706177
epoch: 84--------- train_loss: 1.032943844795227
epoch: 85--------- train_loss: 1.0292961597442627
epoch: 86--------- train_loss: 1.0196596384048462
epoch: 87--------- train_loss: 1.0113670825958252
epoch: 88--------- train_loss: 0.9974216222763062
epoch: 89--------- train_loss: 0.98499995470047
epoch: 90--------- train_loss: 0.9796658158302307
epoch: 91--------- train_loss: 0.9606000781059265
epoch: 92--------- train_loss: 0.9478810429573059
epoch: 93--------- train_loss: 0.9272077679634094
epoch: 94--------- train_loss: 0.9198254346847534
epoch: 95--------- train_loss: 0.9038220643997192
epoch: 96--------- train_loss: 0.9005798101425171
epoch: 97--------- train_loss: 0.8890212178230286
epoch: 98--------- train_loss: 0.8739617466926575
epoch: 99--------- train_loss: 0.8735610842704773
epoch: 100--------- train_loss: 0.8647646307945251
epoch: 101--------- train_loss: 0.8546155691146851
epoch: 102--------- train_loss: 0.8547095060348511
epoch: 103--------- train_loss: 0.8546010851860046
epoch: 104--------- train_loss: 0.8422030210494995
epoch: 105--------- train_loss: 0.8464217185974121
epoch: 106--------- train_loss: 0.8353589773178101
epoch: 107--------- train_loss: 0.8308107852935791
epoch: 108--------- train_loss: 0.8490078449249268
epoch: 109--------- train_loss: 0.8409370183944702
epoch: 110--------- train_loss: 0.8522000312805176
epoch: 111--------- train_loss: 0.8542135953903198
epoch: 112--------- train_loss: 0.858505129814148
epoch: 113--------- train_loss: 0.8565750122070312
epoch: 114--------- train_loss: 0.8535882234573364
epoch: 115--------- train_loss: 0.8716893196105957
epoch: 116--------- train_loss: 0.8684724569320679
epoch: 117--------- train_loss: 0.86031174659729
epoch: 118--------- train_loss: 0.8729984164237976
epoch: 119--------- train_loss: 0.8789218068122864
epoch: 120--------- train_loss: 0.8768653869628906
epoch: 121--------- train_loss: 0.8803009986877441
epoch: 122--------- train_loss: 0.8758901953697205
epoch: 123--------- train_loss: 0.8680076003074646
epoch: 124--------- train_loss: 0.9213659167289734
epoch: 125--------- train_loss: 0.8922339677810669
epoch: 126--------- train_loss: 0.8952571153640747
epoch: 127--------- train_loss: 0.915996789932251
epoch: 128--------- train_loss: 0.9095261693000793
epoch: 129--------- train_loss: 0.9145721197128296
epoch: 130--------- train_loss: 0.9329050183296204
epoch: 131--------- train_loss: 0.9420244693756104
epoch: 132--------- train_loss: 0.9759279489517212
epoch: 133--------- train_loss: 0.9612208604812622
epoch: 134--------- train_loss: 1.0148578882217407
epoch: 135--------- train_loss: 1.017714023590088
epoch: 136--------- train_loss: 1.0056442022323608
epoch: 137--------- train_loss: 1.049005150794983
epoch: 138--------- train_loss: 1.0377631187438965
epoch: 139--------- train_loss: 1.0589417219161987
epoch: 140--------- train_loss: 1.0637260675430298
epoch: 141--------- train_loss: 1.0624759197235107
epoch: 142--------- train_loss: 1.0590428113937378
epoch: 143--------- train_loss: 1.076272964477539
epoch: 144--------- train_loss: 1.085397720336914
epoch: 145--------- train_loss: 1.1108171939849854
epoch: 146--------- train_loss: 1.1015304327011108
epoch: 147--------- train_loss: 1.0986555814743042
epoch: 148--------- train_loss: 1.0936344861984253
epoch: 149--------- train_loss: 1.1544147729873657
epoch: 150--------- train_loss: 1.1346135139465332
epoch: 151--------- train_loss: 1.1773141622543335
epoch: 152--------- train_loss: 1.171181559562683
epoch: 153--------- train_loss: 1.17069673538208
epoch: 154--------- train_loss: 1.1952977180480957
epoch: 155--------- train_loss: 1.1916481256484985
epoch: 156--------- train_loss: 1.1977431774139404
epoch: 157--------- train_loss: 1.253653645515442
epoch: 158--------- train_loss: 1.2450007200241089
epoch: 159--------- train_loss: 1.2711148262023926
epoch: 160--------- train_loss: 1.279634714126587
epoch: 161--------- train_loss: 1.2626432180404663
epoch: 162--------- train_loss: 1.2679404020309448
epoch: 163--------- train_loss: 1.3012813329696655
epoch: 164--------- train_loss: 1.3277591466903687
epoch: 165--------- train_loss: 1.3398005962371826
epoch: 166--------- train_loss: 1.3686333894729614
epoch: 167--------- train_loss: 1.3466132879257202
epoch: 168--------- train_loss: 1.3768500089645386
epoch: 169--------- train_loss: 1.4170327186584473
epoch: 170--------- train_loss: 1.3868263959884644
epoch: 171--------- train_loss: 1.4497525691986084
epoch: 172--------- train_loss: 1.405731201171875
epoch: 173--------- train_loss: 1.4586598873138428
epoch: 174--------- train_loss: 1.4076329469680786
epoch: 175--------- train_loss: 1.441720962524414
epoch: 176--------- train_loss: 1.4734340906143188
epoch: 177--------- train_loss: 1.4529218673706055
epoch: 178--------- train_loss: 1.4888806343078613
epoch: 179--------- train_loss: 1.4677352905273438
epoch: 180--------- train_loss: 1.511913776397705
epoch: 181--------- train_loss: 1.4722340106964111
epoch: 182--------- train_loss: 1.4752321243286133
epoch: 183--------- train_loss: 1.4925403594970703
epoch: 184--------- train_loss: 1.5019607543945312
epoch: 185--------- train_loss: 1.4999698400497437
epoch: 186--------- train_loss: 1.4550631046295166
epoch: 187--------- train_loss: 1.4393846988677979
epoch: 188--------- train_loss: 1.4319093227386475
epoch: 189--------- train_loss: 1.4591155052185059
epoch: 190--------- train_loss: 1.4168972969055176
epoch: 191--------- train_loss: 1.4437847137451172
epoch: 192--------- train_loss: 1.478003978729248
epoch: 193--------- train_loss: 1.4363024234771729
epoch: 194--------- train_loss: 1.4441893100738525
epoch: 195--------- train_loss: 1.426897644996643
epoch: 196--------- train_loss: 1.4398305416107178
epoch: 197--------- train_loss: 1.4886419773101807
epoch: 198--------- train_loss: 1.4061262607574463
epoch: 199--------- train_loss: 1.4181461334228516
epoch: 0--------- train_loss: 4.098881721496582
epoch: 1--------- train_loss: 3.4949228763580322
epoch: 2--------- train_loss: 3.1574594974517822
epoch: 3--------- train_loss: 2.8983917236328125
epoch: 4--------- train_loss: 2.701201915740967
epoch: 5--------- train_loss: 2.5693020820617676
epoch: 6--------- train_loss: 2.477238655090332
epoch: 7--------- train_loss: 2.4189980030059814
epoch: 8--------- train_loss: 2.3838839530944824
epoch: 9--------- train_loss: 2.3529934883117676
epoch: 10--------- train_loss: 2.3232028484344482
epoch: 11--------- train_loss: 2.2944939136505127
epoch: 12--------- train_loss: 2.268404006958008
epoch: 13--------- train_loss: 2.2464892864227295
epoch: 14--------- train_loss: 2.222123622894287
epoch: 15--------- train_loss: 2.1959176063537598
epoch: 16--------- train_loss: 2.1732900142669678
epoch: 17--------- train_loss: 2.152127742767334
epoch: 18--------- train_loss: 2.129885196685791
epoch: 19--------- train_loss: 2.109332323074341
epoch: 20--------- train_loss: 2.091303825378418
epoch: 21--------- train_loss: 2.0731844902038574
epoch: 22--------- train_loss: 2.0563552379608154
epoch: 23--------- train_loss: 2.0425329208374023
epoch: 24--------- train_loss: 2.029033660888672
epoch: 25--------- train_loss: 2.0157113075256348
epoch: 26--------- train_loss: 2.0016584396362305
epoch: 27--------- train_loss: 1.9862375259399414
epoch: 28--------- train_loss: 1.9719438552856445
epoch: 29--------- train_loss: 1.9597344398498535
epoch: 30--------- train_loss: 1.9468002319335938
epoch: 31--------- train_loss: 1.9355374574661255
epoch: 32--------- train_loss: 1.915879249572754
epoch: 33--------- train_loss: 1.9071369171142578
epoch: 34--------- train_loss: 1.891028881072998
epoch: 35--------- train_loss: 1.8767869472503662
epoch: 36--------- train_loss: 1.8599050045013428
epoch: 37--------- train_loss: 1.8486863374710083
epoch: 38--------- train_loss: 1.8358728885650635
epoch: 39--------- train_loss: 1.8271853923797607
epoch: 40--------- train_loss: 1.8149714469909668
epoch: 41--------- train_loss: 1.8040858507156372
epoch: 42--------- train_loss: 1.7909321784973145
epoch: 43--------- train_loss: 1.7773858308792114
epoch: 44--------- train_loss: 1.7682862281799316
epoch: 45--------- train_loss: 1.7562236785888672
epoch: 46--------- train_loss: 1.7419652938842773
epoch: 47--------- train_loss: 1.731742024421692
epoch: 48--------- train_loss: 1.7207657098770142
epoch: 49--------- train_loss: 1.7041866779327393
epoch: 50--------- train_loss: 1.6971256732940674
epoch: 51--------- train_loss: 1.6837810277938843
epoch: 52--------- train_loss: 1.6740646362304688
epoch: 53--------- train_loss: 1.658445119857788
epoch: 54--------- train_loss: 1.6578648090362549
epoch: 55--------- train_loss: 1.6382827758789062
epoch: 56--------- train_loss: 1.6290593147277832
epoch: 57--------- train_loss: 1.6122041940689087
epoch: 58--------- train_loss: 1.5997169017791748
epoch: 59--------- train_loss: 1.5852243900299072
epoch: 60--------- train_loss: 1.5704803466796875
epoch: 61--------- train_loss: 1.5639405250549316
epoch: 62--------- train_loss: 1.553497314453125
epoch: 63--------- train_loss: 1.5430362224578857
epoch: 64--------- train_loss: 1.5329509973526
epoch: 65--------- train_loss: 1.5163323879241943
epoch: 66--------- train_loss: 1.5003373622894287
epoch: 67--------- train_loss: 1.4947986602783203
epoch: 68--------- train_loss: 1.4852021932601929
epoch: 69--------- train_loss: 1.4748992919921875
epoch: 70--------- train_loss: 1.4699389934539795
epoch: 71--------- train_loss: 1.4555823802947998
epoch: 72--------- train_loss: 1.4493625164031982
epoch: 73--------- train_loss: 1.4367377758026123
epoch: 74--------- train_loss: 1.427288293838501
epoch: 75--------- train_loss: 1.4197146892547607
epoch: 76--------- train_loss: 1.4129023551940918
epoch: 77--------- train_loss: 1.4042584896087646
epoch: 78--------- train_loss: 1.4027152061462402
epoch: 79--------- train_loss: 1.4039838314056396
epoch: 80--------- train_loss: 1.404468059539795
epoch: 81--------- train_loss: 1.3894072771072388
epoch: 82--------- train_loss: 1.3833982944488525
epoch: 83--------- train_loss: 1.37611985206604
epoch: 84--------- train_loss: 1.3738043308258057
epoch: 85--------- train_loss: 1.354156255722046
epoch: 86--------- train_loss: 1.3554613590240479
epoch: 87--------- train_loss: 1.3512334823608398
epoch: 88--------- train_loss: 1.3509893417358398
epoch: 89--------- train_loss: 1.3450372219085693
epoch: 90--------- train_loss: 1.3338485956192017
epoch: 91--------- train_loss: 1.3286118507385254
epoch: 92--------- train_loss: 1.3060914278030396
epoch: 93--------- train_loss: 1.2955069541931152
epoch: 94--------- train_loss: 1.2832787036895752
epoch: 95--------- train_loss: 1.2823671102523804
epoch: 96--------- train_loss: 1.259247064590454
epoch: 97--------- train_loss: 1.2487057447433472
epoch: 98--------- train_loss: 1.2389590740203857
epoch: 99--------- train_loss: 1.2209421396255493
epoch: 100--------- train_loss: 1.2178680896759033
epoch: 101--------- train_loss: 1.212446928024292
epoch: 102--------- train_loss: 1.2140343189239502
epoch: 103--------- train_loss: 1.206284999847412
epoch: 104--------- train_loss: 1.1869025230407715
epoch: 105--------- train_loss: 1.1702609062194824
epoch: 106--------- train_loss: 1.1877379417419434
epoch: 107--------- train_loss: 1.164475440979004
epoch: 108--------- train_loss: 1.1779491901397705
epoch: 109--------- train_loss: 1.1707284450531006
epoch: 110--------- train_loss: 1.173349380493164
epoch: 111--------- train_loss: 1.1685233116149902
epoch: 112--------- train_loss: 1.1734676361083984
epoch: 113--------- train_loss: 1.1610983610153198
epoch: 114--------- train_loss: 1.1752629280090332
epoch: 115--------- train_loss: 1.1699445247650146
epoch: 116--------- train_loss: 1.166784644126892
epoch: 117--------- train_loss: 1.1794185638427734
epoch: 118--------- train_loss: 1.171344518661499
epoch: 119--------- train_loss: 1.1638314723968506
epoch: 120--------- train_loss: 1.1631059646606445
epoch: 121--------- train_loss: 1.1665880680084229
epoch: 122--------- train_loss: 1.154590129852295
epoch: 123--------- train_loss: 1.146895408630371
epoch: 124--------- train_loss: 1.1488676071166992
epoch: 125--------- train_loss: 1.129173755645752
epoch: 126--------- train_loss: 1.1374138593673706
epoch: 127--------- train_loss: 1.1156120300292969
epoch: 128--------- train_loss: 1.1022861003875732
epoch: 129--------- train_loss: 1.0994906425476074
epoch: 130--------- train_loss: 1.0913125276565552
epoch: 131--------- train_loss: 1.1109073162078857
epoch: 132--------- train_loss: 1.113074779510498
epoch: 133--------- train_loss: 1.1059147119522095
epoch: 134--------- train_loss: 1.097624659538269
epoch: 135--------- train_loss: 1.1112626791000366
epoch: 136--------- train_loss: 1.1175727844238281
epoch: 137--------- train_loss: 1.1262543201446533
epoch: 138--------- train_loss: 1.1241861581802368
epoch: 139--------- train_loss: 1.1386597156524658
epoch: 140--------- train_loss: 1.1418288946151733
epoch: 141--------- train_loss: 1.1500959396362305
epoch: 142--------- train_loss: 1.1583963632583618
epoch: 143--------- train_loss: 1.2082171440124512
epoch: 144--------- train_loss: 1.1568365097045898
epoch: 145--------- train_loss: 1.184189796447754
epoch: 146--------- train_loss: 1.1963212490081787
epoch: 147--------- train_loss: 1.1961498260498047
epoch: 148--------- train_loss: 1.191399335861206
epoch: 149--------- train_loss: 1.2097127437591553
epoch: 150--------- train_loss: 1.1983716487884521
epoch: 151--------- train_loss: 1.2205491065979004
epoch: 152--------- train_loss: 1.2019554376602173
epoch: 153--------- train_loss: 1.1968950033187866
epoch: 154--------- train_loss: 1.205980896949768
epoch: 155--------- train_loss: 1.2148897647857666
epoch: 156--------- train_loss: 1.1860454082489014
epoch: 157--------- train_loss: 1.1876027584075928
epoch: 158--------- train_loss: 1.204228401184082
epoch: 159--------- train_loss: 1.1924535036087036
epoch: 160--------- train_loss: 1.1845886707305908
epoch: 161--------- train_loss: 1.184722900390625
epoch: 162--------- train_loss: 1.1880933046340942
epoch: 163--------- train_loss: 1.2001639604568481
epoch: 164--------- train_loss: 1.2773127555847168
epoch: 165--------- train_loss: 1.253706455230713
epoch: 166--------- train_loss: 1.2328269481658936
epoch: 167--------- train_loss: 1.2634954452514648
epoch: 168--------- train_loss: 1.2671334743499756
epoch: 169--------- train_loss: 1.2595781087875366
epoch: 170--------- train_loss: 1.2493677139282227
epoch: 171--------- train_loss: 1.2632911205291748
epoch: 172--------- train_loss: 1.2566869258880615
epoch: 173--------- train_loss: 1.2467195987701416
epoch: 174--------- train_loss: 1.2710156440734863
epoch: 175--------- train_loss: 1.226163625717163
epoch: 176--------- train_loss: 1.246425986289978
epoch: 177--------- train_loss: 1.2870252132415771
epoch: 178--------- train_loss: 1.2900989055633545
epoch: 179--------- train_loss: 1.319770336151123
epoch: 180--------- train_loss: 1.3939297199249268
epoch: 181--------- train_loss: 1.306915283203125
epoch: 182--------- train_loss: 1.3548500537872314
epoch: 183--------- train_loss: 1.3411803245544434
epoch: 184--------- train_loss: 1.4233452081680298
epoch: 185--------- train_loss: 1.4145324230194092
epoch: 186--------- train_loss: 1.4422699213027954
epoch: 187--------- train_loss: 1.4036684036254883
epoch: 188--------- train_loss: 1.441145420074463
epoch: 189--------- train_loss: 1.4099258184432983
epoch: 190--------- train_loss: 1.4493119716644287
epoch: 191--------- train_loss: 1.3899587392807007
epoch: 192--------- train_loss: 1.4335441589355469
epoch: 193--------- train_loss: 1.432044267654419
epoch: 194--------- train_loss: 1.434984564781189
epoch: 195--------- train_loss: 1.419633388519287
epoch: 196--------- train_loss: 1.4019181728363037
epoch: 197--------- train_loss: 1.3907313346862793
epoch: 198--------- train_loss: 1.4344137907028198
epoch: 199--------- train_loss: 1.4007384777069092
epoch: 0--------- train_loss: 203.7524871826172
epoch: 1--------- train_loss: 192.57931518554688
epoch: 2--------- train_loss: 183.45860290527344
epoch: 3--------- train_loss: 176.3208770751953
epoch: 4--------- train_loss: 171.14976501464844
epoch: 5--------- train_loss: 167.70095825195312
epoch: 6--------- train_loss: 165.5286407470703
epoch: 7--------- train_loss: 164.31381225585938
epoch: 8--------- train_loss: 163.71157836914062
epoch: 9--------- train_loss: 163.5325164794922
epoch: 10--------- train_loss: 163.51959228515625
epoch: 11--------- train_loss: 163.62115478515625
epoch: 12--------- train_loss: 163.6856689453125
epoch: 13--------- train_loss: 163.74520874023438
epoch: 14--------- train_loss: 163.85499572753906
epoch: 15--------- train_loss: 163.97232055664062
epoch: 16--------- train_loss: 163.98377990722656
epoch: 17--------- train_loss: 164.1482391357422
epoch: 18--------- train_loss: 164.18394470214844
epoch: 19--------- train_loss: 164.16783142089844
epoch: 20--------- train_loss: 164.23756408691406
epoch: 21--------- train_loss: 164.28140258789062
epoch: 22--------- train_loss: 164.29409790039062
epoch: 23--------- train_loss: 164.32191467285156
epoch: 24--------- train_loss: 164.29547119140625
epoch: 25--------- train_loss: 164.31317138671875
epoch: 26--------- train_loss: 164.26547241210938
epoch: 27--------- train_loss: 164.255126953125
epoch: 28--------- train_loss: 164.23947143554688
epoch: 29--------- train_loss: 164.21295166015625
epoch: 30--------- train_loss: 164.21990966796875
epoch: 31--------- train_loss: 164.1996307373047
epoch: 32--------- train_loss: 164.1756134033203
epoch: 33--------- train_loss: 164.1614227294922
epoch: 34--------- train_loss: 164.1796112060547
epoch: 35--------- train_loss: 164.1051025390625
epoch: 36--------- train_loss: 164.13360595703125
epoch: 37--------- train_loss: 164.13815307617188
epoch: 38--------- train_loss: 164.20285034179688
epoch: 39--------- train_loss: 164.16458129882812
epoch: 40--------- train_loss: 164.1182861328125
epoch: 41--------- train_loss: 164.12876892089844
epoch: 42--------- train_loss: 164.12777709960938
epoch: 43--------- train_loss: 164.10986328125
epoch: 44--------- train_loss: 164.06527709960938
epoch: 45--------- train_loss: 164.07708740234375
epoch: 46--------- train_loss: 164.0542449951172
epoch: 47--------- train_loss: 163.99545288085938
epoch: 48--------- train_loss: 163.99462890625
epoch: 49--------- train_loss: 163.98843383789062
epoch: 50--------- train_loss: 163.94024658203125
epoch: 51--------- train_loss: 163.86737060546875
epoch: 52--------- train_loss: 163.88568115234375
epoch: 53--------- train_loss: 163.84092712402344
epoch: 54--------- train_loss: 163.81167602539062
epoch: 55--------- train_loss: 163.79209899902344
epoch: 56--------- train_loss: 163.71591186523438
epoch: 57--------- train_loss: 163.69964599609375
epoch: 58--------- train_loss: 163.63131713867188
epoch: 59--------- train_loss: 163.55178833007812
epoch: 60--------- train_loss: 163.5171356201172
epoch: 61--------- train_loss: 163.44525146484375
epoch: 62--------- train_loss: 163.40280151367188
epoch: 63--------- train_loss: 163.41909790039062
epoch: 64--------- train_loss: 163.330322265625
epoch: 65--------- train_loss: 163.2834930419922
epoch: 66--------- train_loss: 163.22821044921875
epoch: 67--------- train_loss: 163.04856872558594
epoch: 68--------- train_loss: 162.95355224609375
epoch: 69--------- train_loss: 162.78750610351562
epoch: 70--------- train_loss: 162.78407287597656
epoch: 71--------- train_loss: 162.7694549560547
epoch: 72--------- train_loss: 162.6355438232422
epoch: 73--------- train_loss: 162.63909912109375
epoch: 74--------- train_loss: 162.52772521972656
epoch: 75--------- train_loss: 162.49722290039062
epoch: 76--------- train_loss: 162.457275390625
epoch: 77--------- train_loss: 162.34539794921875
epoch: 78--------- train_loss: 162.32960510253906
epoch: 79--------- train_loss: 162.19725036621094
epoch: 80--------- train_loss: 162.0994873046875
epoch: 81--------- train_loss: 162.02420043945312
epoch: 82--------- train_loss: 162.0056915283203
epoch: 83--------- train_loss: 161.87777709960938
epoch: 84--------- train_loss: 161.81695556640625
epoch: 85--------- train_loss: 161.669189453125
epoch: 86--------- train_loss: 161.62127685546875
epoch: 87--------- train_loss: 161.6337890625
epoch: 88--------- train_loss: 161.44418334960938
epoch: 89--------- train_loss: 161.5666046142578
epoch: 90--------- train_loss: 161.45074462890625
epoch: 91--------- train_loss: 161.53915405273438
epoch: 92--------- train_loss: 161.406982421875
epoch: 93--------- train_loss: 161.32017517089844
epoch: 94--------- train_loss: 161.3290252685547
epoch: 95--------- train_loss: 161.20223999023438
epoch: 96--------- train_loss: 161.22311401367188
epoch: 97--------- train_loss: 161.17984008789062
epoch: 98--------- train_loss: 160.9474334716797
epoch: 99--------- train_loss: 161.0743408203125
epoch: 100--------- train_loss: 160.8528289794922
epoch: 101--------- train_loss: 160.91055297851562
epoch: 102--------- train_loss: 160.87326049804688
epoch: 103--------- train_loss: 160.74229431152344
epoch: 104--------- train_loss: 160.68215942382812
epoch: 105--------- train_loss: 160.61781311035156
epoch: 106--------- train_loss: 160.69882202148438
epoch: 107--------- train_loss: 160.639404296875
epoch: 108--------- train_loss: 160.48373413085938
epoch: 109--------- train_loss: 160.37750244140625
epoch: 110--------- train_loss: 160.40902709960938
epoch: 111--------- train_loss: 160.29055786132812
epoch: 112--------- train_loss: 160.11004638671875
epoch: 113--------- train_loss: 159.9518280029297
epoch: 114--------- train_loss: 159.86135864257812
epoch: 115--------- train_loss: 159.74102783203125
epoch: 116--------- train_loss: 159.86508178710938
epoch: 117--------- train_loss: 159.963134765625
epoch: 118--------- train_loss: 159.81192016601562
epoch: 119--------- train_loss: 159.6533203125
epoch: 120--------- train_loss: 159.59320068359375
epoch: 121--------- train_loss: 159.76809692382812
epoch: 122--------- train_loss: 159.43106079101562
epoch: 123--------- train_loss: 159.36135864257812
epoch: 124--------- train_loss: 159.27133178710938
epoch: 125--------- train_loss: 159.30953979492188
epoch: 126--------- train_loss: 159.08651733398438
epoch: 127--------- train_loss: 159.21229553222656
epoch: 128--------- train_loss: 159.19732666015625
epoch: 129--------- train_loss: 159.08407592773438
epoch: 130--------- train_loss: 159.0550537109375
epoch: 131--------- train_loss: 158.65289306640625
epoch: 132--------- train_loss: 158.68182373046875
epoch: 133--------- train_loss: 158.7796630859375
epoch: 134--------- train_loss: 158.37229919433594
epoch: 135--------- train_loss: 157.93710327148438
epoch: 136--------- train_loss: 158.07286071777344
epoch: 137--------- train_loss: 157.88584899902344
epoch: 138--------- train_loss: 157.69424438476562
epoch: 139--------- train_loss: 157.56903076171875
epoch: 140--------- train_loss: 157.77157592773438
epoch: 141--------- train_loss: 157.8258056640625
epoch: 142--------- train_loss: 157.65463256835938
epoch: 143--------- train_loss: 157.57904052734375
epoch: 144--------- train_loss: 157.69082641601562
epoch: 145--------- train_loss: 157.47665405273438
epoch: 146--------- train_loss: 157.50811767578125
epoch: 147--------- train_loss: 157.62322998046875
epoch: 148--------- train_loss: 157.43133544921875
epoch: 149--------- train_loss: 157.3184814453125
epoch: 150--------- train_loss: 157.04647827148438
epoch: 151--------- train_loss: 157.14459228515625
epoch: 152--------- train_loss: 157.18637084960938
epoch: 153--------- train_loss: 156.94569396972656
epoch: 154--------- train_loss: 157.1630401611328
epoch: 155--------- train_loss: 156.74583435058594
epoch: 156--------- train_loss: 156.8817138671875
epoch: 157--------- train_loss: 156.60110473632812
epoch: 158--------- train_loss: 156.3929901123047
epoch: 159--------- train_loss: 156.07489013671875
epoch: 160--------- train_loss: 156.1021728515625
epoch: 161--------- train_loss: 156.18777465820312
epoch: 162--------- train_loss: 156.1103515625
epoch: 163--------- train_loss: 156.22964477539062
epoch: 164--------- train_loss: 156.27418518066406
epoch: 165--------- train_loss: 156.23538208007812
epoch: 166--------- train_loss: 156.4911346435547
epoch: 167--------- train_loss: 156.5970458984375
epoch: 168--------- train_loss: 156.49099731445312
epoch: 169--------- train_loss: 156.48709106445312
epoch: 170--------- train_loss: 156.68505859375
epoch: 171--------- train_loss: 156.337890625
epoch: 172--------- train_loss: 156.4677734375
epoch: 173--------- train_loss: 156.64276123046875
epoch: 174--------- train_loss: 156.96832275390625
epoch: 175--------- train_loss: 156.76364135742188
epoch: 176--------- train_loss: 157.0216064453125
epoch: 177--------- train_loss: 156.87429809570312
epoch: 178--------- train_loss: 157.12954711914062
epoch: 179--------- train_loss: 157.00973510742188
epoch: 180--------- train_loss: 157.17782592773438
epoch: 181--------- train_loss: 157.06109619140625
epoch: 182--------- train_loss: 157.25643920898438
epoch: 183--------- train_loss: 156.93020629882812
epoch: 184--------- train_loss: 157.15713500976562
epoch: 185--------- train_loss: 157.57192993164062
epoch: 186--------- train_loss: 158.105712890625
epoch: 187--------- train_loss: 158.05722045898438
epoch: 188--------- train_loss: 158.00796508789062
epoch: 189--------- train_loss: 157.96994018554688
epoch: 190--------- train_loss: 158.0557861328125
epoch: 191--------- train_loss: 158.08233642578125
epoch: 192--------- train_loss: 158.02178955078125
epoch: 193--------- train_loss: 158.49908447265625
epoch: 194--------- train_loss: 158.196533203125
epoch: 195--------- train_loss: 158.610107421875
epoch: 196--------- train_loss: 158.59609985351562
epoch: 197--------- train_loss: 158.56915283203125
epoch: 198--------- train_loss: 158.94625854492188
epoch: 199--------- train_loss: 159.01498413085938
epoch: 0--------- train_loss: 170.78411865234375
epoch: 1--------- train_loss: 168.9678955078125
epoch: 2--------- train_loss: 167.7109375
epoch: 3--------- train_loss: 166.72109985351562
epoch: 4--------- train_loss: 165.94180297851562
epoch: 5--------- train_loss: 165.33920288085938
epoch: 6--------- train_loss: 164.76869201660156
epoch: 7--------- train_loss: 164.290283203125
epoch: 8--------- train_loss: 163.8287353515625
epoch: 9--------- train_loss: 163.41116333007812
epoch: 10--------- train_loss: 163.05152893066406
epoch: 11--------- train_loss: 162.69509887695312
epoch: 12--------- train_loss: 162.3941650390625
epoch: 13--------- train_loss: 162.13023376464844
epoch: 14--------- train_loss: 161.89186096191406
epoch: 15--------- train_loss: 161.69058227539062
epoch: 16--------- train_loss: 161.48660278320312
epoch: 17--------- train_loss: 161.31524658203125
epoch: 18--------- train_loss: 161.16903686523438
epoch: 19--------- train_loss: 160.98861694335938
epoch: 20--------- train_loss: 160.82833862304688
epoch: 21--------- train_loss: 160.671142578125
epoch: 22--------- train_loss: 160.5648956298828
epoch: 23--------- train_loss: 160.40249633789062
epoch: 24--------- train_loss: 160.2608642578125
epoch: 25--------- train_loss: 160.12777709960938
epoch: 26--------- train_loss: 159.9759521484375
epoch: 27--------- train_loss: 159.8343505859375
epoch: 28--------- train_loss: 159.72982788085938
epoch: 29--------- train_loss: 159.6064453125
epoch: 30--------- train_loss: 159.50038146972656
epoch: 31--------- train_loss: 159.36874389648438
epoch: 32--------- train_loss: 159.2584228515625
epoch: 33--------- train_loss: 159.15322875976562
epoch: 34--------- train_loss: 159.05047607421875
epoch: 35--------- train_loss: 158.97076416015625
epoch: 36--------- train_loss: 158.89083862304688
epoch: 37--------- train_loss: 158.77978515625
epoch: 38--------- train_loss: 158.61190795898438
epoch: 39--------- train_loss: 158.52822875976562
epoch: 40--------- train_loss: 158.42813110351562
epoch: 41--------- train_loss: 158.34112548828125
epoch: 42--------- train_loss: 158.20904541015625
epoch: 43--------- train_loss: 158.057861328125
epoch: 44--------- train_loss: 157.91082763671875
epoch: 45--------- train_loss: 157.7660675048828
epoch: 46--------- train_loss: 157.66436767578125
epoch: 47--------- train_loss: 157.5380859375
epoch: 48--------- train_loss: 157.41200256347656
epoch: 49--------- train_loss: 157.31509399414062
epoch: 50--------- train_loss: 157.2198028564453
epoch: 51--------- train_loss: 157.13897705078125
epoch: 52--------- train_loss: 157.04769897460938
epoch: 53--------- train_loss: 156.92193603515625
epoch: 54--------- train_loss: 156.81483459472656
epoch: 55--------- train_loss: 156.75045776367188
epoch: 56--------- train_loss: 156.57489013671875
epoch: 57--------- train_loss: 156.50296020507812
epoch: 58--------- train_loss: 156.4171142578125
epoch: 59--------- train_loss: 156.33700561523438
epoch: 60--------- train_loss: 156.2886505126953
epoch: 61--------- train_loss: 156.2421417236328
epoch: 62--------- train_loss: 156.16619873046875
epoch: 63--------- train_loss: 156.12936401367188
epoch: 64--------- train_loss: 156.04872131347656
epoch: 65--------- train_loss: 156.00643920898438
epoch: 66--------- train_loss: 155.8885498046875
epoch: 67--------- train_loss: 155.80247497558594
epoch: 68--------- train_loss: 155.62973022460938
epoch: 69--------- train_loss: 155.56236267089844
epoch: 70--------- train_loss: 155.469970703125
epoch: 71--------- train_loss: 155.341064453125
epoch: 72--------- train_loss: 155.31719970703125
epoch: 73--------- train_loss: 155.2066192626953
epoch: 74--------- train_loss: 155.1005859375
epoch: 75--------- train_loss: 155.04312133789062
epoch: 76--------- train_loss: 154.97323608398438
epoch: 77--------- train_loss: 154.959228515625
epoch: 78--------- train_loss: 154.84970092773438
epoch: 79--------- train_loss: 154.8318634033203
epoch: 80--------- train_loss: 154.8233642578125
epoch: 81--------- train_loss: 154.7728271484375
epoch: 82--------- train_loss: 154.80856323242188
epoch: 83--------- train_loss: 154.70196533203125
epoch: 84--------- train_loss: 154.72698974609375
epoch: 85--------- train_loss: 154.59332275390625
epoch: 86--------- train_loss: 154.50033569335938
epoch: 87--------- train_loss: 154.48727416992188
epoch: 88--------- train_loss: 154.5081024169922
epoch: 89--------- train_loss: 154.57940673828125
epoch: 90--------- train_loss: 154.5652313232422
epoch: 91--------- train_loss: 154.55276489257812
epoch: 92--------- train_loss: 154.4775390625
epoch: 93--------- train_loss: 154.52777099609375
epoch: 94--------- train_loss: 154.45578002929688
epoch: 95--------- train_loss: 154.50894165039062
epoch: 96--------- train_loss: 154.508056640625
epoch: 97--------- train_loss: 154.44805908203125
epoch: 98--------- train_loss: 154.5089111328125
epoch: 99--------- train_loss: 154.52243041992188
epoch: 100--------- train_loss: 154.56167602539062
epoch: 101--------- train_loss: 154.54066467285156
epoch: 102--------- train_loss: 154.58474731445312
epoch: 103--------- train_loss: 154.7332763671875
epoch: 104--------- train_loss: 154.66366577148438
epoch: 105--------- train_loss: 154.73544311523438
epoch: 106--------- train_loss: 154.77450561523438
epoch: 107--------- train_loss: 154.78732299804688
epoch: 108--------- train_loss: 154.82711791992188
epoch: 109--------- train_loss: 154.78167724609375
epoch: 110--------- train_loss: 154.9208221435547
epoch: 111--------- train_loss: 154.82363891601562
epoch: 112--------- train_loss: 154.90451049804688
epoch: 113--------- train_loss: 154.897216796875
epoch: 114--------- train_loss: 154.8101806640625
epoch: 115--------- train_loss: 154.81378173828125
epoch: 116--------- train_loss: 155.05502319335938
epoch: 117--------- train_loss: 154.9617919921875
epoch: 118--------- train_loss: 155.093994140625
epoch: 119--------- train_loss: 154.99530029296875
epoch: 120--------- train_loss: 155.12252807617188
epoch: 121--------- train_loss: 155.22862243652344
epoch: 122--------- train_loss: 155.30572509765625
epoch: 123--------- train_loss: 155.2379150390625
epoch: 124--------- train_loss: 155.44943237304688
epoch: 125--------- train_loss: 155.427978515625
epoch: 126--------- train_loss: 155.43165588378906
epoch: 127--------- train_loss: 155.5576629638672
epoch: 128--------- train_loss: 155.58340454101562
epoch: 129--------- train_loss: 155.4083251953125
epoch: 130--------- train_loss: 155.46920776367188
epoch: 131--------- train_loss: 155.60279846191406
epoch: 132--------- train_loss: 155.8372802734375
epoch: 133--------- train_loss: 155.59422302246094
epoch: 134--------- train_loss: 155.67178344726562
epoch: 135--------- train_loss: 155.67596435546875
epoch: 136--------- train_loss: 155.7296142578125
epoch: 137--------- train_loss: 155.5834503173828
epoch: 138--------- train_loss: 155.6231689453125
epoch: 139--------- train_loss: 155.79217529296875
epoch: 140--------- train_loss: 155.73220825195312
epoch: 141--------- train_loss: 155.62164306640625
epoch: 142--------- train_loss: 155.8623046875
epoch: 143--------- train_loss: 155.78582763671875
epoch: 144--------- train_loss: 155.95494079589844
epoch: 145--------- train_loss: 155.97178649902344
epoch: 146--------- train_loss: 155.99378967285156
epoch: 147--------- train_loss: 156.29373168945312
epoch: 148--------- train_loss: 156.17190551757812
epoch: 149--------- train_loss: 156.05233764648438
epoch: 150--------- train_loss: 156.51312255859375
epoch: 151--------- train_loss: 156.2822265625
epoch: 152--------- train_loss: 156.45069885253906
epoch: 153--------- train_loss: 156.2298583984375
epoch: 154--------- train_loss: 156.31739807128906
epoch: 155--------- train_loss: 156.50888061523438
epoch: 156--------- train_loss: 156.54901123046875
epoch: 157--------- train_loss: 156.66566467285156
epoch: 158--------- train_loss: 156.60025024414062
epoch: 159--------- train_loss: 156.64710998535156
epoch: 160--------- train_loss: 156.56625366210938
epoch: 161--------- train_loss: 156.73855590820312
epoch: 162--------- train_loss: 156.81732177734375
epoch: 163--------- train_loss: 156.968017578125
epoch: 164--------- train_loss: 156.8150634765625
epoch: 165--------- train_loss: 157.0191650390625
epoch: 166--------- train_loss: 156.97479248046875
epoch: 167--------- train_loss: 157.0957794189453
epoch: 168--------- train_loss: 157.0272216796875
epoch: 169--------- train_loss: 157.15455627441406
epoch: 170--------- train_loss: 157.20819091796875
epoch: 171--------- train_loss: 157.2343292236328
epoch: 172--------- train_loss: 157.47967529296875
epoch: 173--------- train_loss: 157.04042053222656
epoch: 174--------- train_loss: 157.56361389160156
epoch: 175--------- train_loss: 157.58335876464844
epoch: 176--------- train_loss: 157.4888916015625
epoch: 177--------- train_loss: 157.2252197265625
epoch: 178--------- train_loss: 157.46661376953125
epoch: 179--------- train_loss: 157.46051025390625
epoch: 180--------- train_loss: 157.2972412109375
epoch: 181--------- train_loss: 157.41943359375
epoch: 182--------- train_loss: 157.4495086669922
epoch: 183--------- train_loss: 157.2739715576172
epoch: 184--------- train_loss: 157.25030517578125
epoch: 185--------- train_loss: 156.91934204101562
epoch: 186--------- train_loss: 157.02313232421875
epoch: 187--------- train_loss: 156.91964721679688
epoch: 188--------- train_loss: 157.05523681640625
epoch: 189--------- train_loss: 156.9873046875
epoch: 190--------- train_loss: 157.11354064941406
epoch: 191--------- train_loss: 156.91677856445312
epoch: 192--------- train_loss: 156.78289794921875
epoch: 193--------- train_loss: 156.8233184814453
epoch: 194--------- train_loss: 156.22528076171875
epoch: 195--------- train_loss: 156.6103973388672
epoch: 196--------- train_loss: 156.21148681640625
epoch: 197--------- train_loss: 156.2154998779297
epoch: 198--------- train_loss: 156.0496826171875
epoch: 199--------- train_loss: 155.88897705078125
[(-0.006768533, (-0.007682157365764247, -0.005854908691560162)), (-0.95558256, (-0.9572514981383824, -0.9539136200790859)), (0.26396698, (0.2625878772134719, 0.26534607797909404)), (-0.42949328, (-0.43114973331242185, -0.42783682321757693))]
